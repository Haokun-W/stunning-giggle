
ChatGPT掀起了一股AI的大潮，我很多非IT的朋友都来问我，看ChatGPT能否在他们的工作上提供一定的帮助。我今天就大概来聊一下，ChatGPT是个什么样的技术，发展历史是什么，为什么突然就爆火起来了。人工智能相关的产品，大家比较熟悉的可能是16-17年的Alpha-Go，过了六七年，ChatGPT又成了一个现象级产品。

人工智能，或者说强人工智能，是否能取代人类，或者人类的工作，生活会产生多大的变化？

先说GPT的概念，GPT是NLP 自然语言处理领域的一个大模型，所以先从NLP领域开始讲，看看近10年NLP的发展，可能会更好理解ChatGPT和别的产品的区别。

2012年是深度学习火起来的一年，在这之前，NLP的应用基本是基于规则，或者统计学的一些方法，比如n-gram，它通过对历史文本进行统计，预测下一个可能出现的单词或短语，和chatGPT的理念相似。2013年Google发表了一篇论文《Word2Vec》，将深度学习引入了NLP领域，该文章将每个单词，每句话变成一个数字或者向量，再将这些向量放到深度学习模型中训练，去拟合各类任务，比如分类，抽取关键信息，翻译，都是基于这种逻辑。2013年之后，基于规则的NLP渐渐被废弃，大家都开始用深度学习。针对不同的问题，深度学习需要设计不同的模型，去收集数据，调参，非常消耗人力物力，当时算法工程师这个岗位特别稀缺。

2017年，Google又发了一篇论文，提出了一个叫Transformer的模型，一开始是在机器翻译领域提出的，引出了一个强大的结构，或者说大模型这个理念，可以用一个模型去拟合各种任务。

模型有了还需要数据，才能让模型学习到有用的知识。18年之前行业主流是人工标注的方式，告诉模型那些数据的结果是什么。大模型又需要大量标注数据，更加费时费力。在2018年，Google出了一个新的成果，叫Bert，这个模型非常有里程碑意义。不需要人工标注，互联网上就有大量已经标注的，有效的数据，像Twitter，Wiki，将这些数据丢到模型里去训练，就得到了一个预训练，pre-trained的模型，一经推出就把各种机器学习的榜单刷到了第一。Bert是个什么效果呢，比如我输入：我是一个非常帅的，Bert会继续说：人。不需要多大的功夫就可以达到一个不错的效果。

2018年后，算法工程师不再去设计模型了，而是用Bert去组织各种数据结构，门槛大大降低了。同期OpenAI，我们的主角终于出现了，也做了相关的工作，叫GPT，比Bert还早几个月但是效果差了很多，没获得太多的关注。GPT和Bert的区别是什么呢，Bert就如上面所说，我是一个非常帅的，它输出：人。GPT呢，我只要输入 我是，它生成一个，再将 我是一个重新作为输入，生成一个非常自恋的人。所以它的任务是更加复杂的，在当时数据量和硬件支持下比不过Google也是情有可原的事情。

之后OpenAI这家公司和Google，包括Facebook，大家都在朝着各自的方向坚持。OpenAI也迭代了几次GPT模型。

2019年发布了GPT2，简单说就是更大的模型，更多的数据，更好的效果，大概15亿参数。

2020年发布了GPT3，1750亿参数，更大更强，但在业界也没掀起什么波浪。

2022年，OpenAI发布了论文，正式发布了GPT3.5/InstructGPT。这个模型在业界有一定的影响力，通过api呢有些公司还完成了上市。在同年11-12月，大家就见证了ChatGPT的诞生。ChatGPT用的是3.5的模型，和GPT3没有本质上的区别。之所以有这么大的区别，第一，OpenAI通过人工标注的方法，让模型生成的语言更加符合人的习惯。第二引入了强化学习，将GPT3和人真正的意图对齐。其实GPT3已经是个很强的模型了，它看过全网的数据，它说出的话逻辑自洽，结构分析，就是说出来的东西不是人们想要的。

2023年，GPT4公布了，为什么当时GPT3之后不直接是GPT4而是3.5呢？GPT3像是一个通过网上已有数据预训练之后的一个模型，GPT4就是这个模型在收集大量chat数据之后的结果。OpenAI人工标注的数据还是有限，因此需要广大的网友去主动帮他们免费提供数据，等到时机成熟了就是GPT4了。

现在2024年，GPT4升级成了GPT4-turbo，再到GPT4o，每一次的迭代主要集中供暖在性能优化和计算效率的提升上。通过蒸馏模型，压缩和剪枝，GPT4o在性能没有缩减的情况下大大地提升了计算的速度，因此我们能看到api调用的费用从$90降到$40，最终变成现在的$20每1 million tokens输入输出。如果不是ChatGPT的深度用户，比起购买$20每个月的plus会员，或许搭建自己的api调用平台会经济实惠很多。